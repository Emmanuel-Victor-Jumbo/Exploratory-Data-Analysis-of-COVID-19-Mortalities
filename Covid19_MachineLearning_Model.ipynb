{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1acacff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import pandas as pd                       #provides a dataframe\n",
    "import urllib.request\n",
    "# NEW (From Covid19_DataSet_Visualisation)\n",
    "import seaborn as sns  \n",
    "import folium                             #For plotting Choropleth Map\n",
    "# NEW (From Covid19_MachineLearning_Model)\n",
    "import json\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a279bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For graph plotting\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# mpl.rc('axes', labelsize=14)\n",
    "# mpl.rc('xtick', labelsize=12)\n",
    "# mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f89913",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a0580ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "C19_View = pd.read_csv('/Users/emmanueljumbo/dataScience/python/Dissertation/experimentation/data/ML_Ultimate_Covid19_DataSet.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28e258db",
   "metadata": {},
   "outputs": [],
   "source": [
    "C19_View = C19_View.drop(\"Unnamed: 0\", axis=1)\n",
    "# C19_View['Date'] = pd.to_datetime(C19_View['Date'])\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)   # Lets you see ALL dataframe ROW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b17baa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Metro_Status</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Population_Density</th>\n",
       "      <th>Cases_pct</th>\n",
       "      <th>Death_pct</th>\n",
       "      <th>EP_POV</th>\n",
       "      <th>EP_UNEMP</th>\n",
       "      <th>EP_PCI</th>\n",
       "      <th>EP_MINRTY</th>\n",
       "      <th>EP_UNINSUR</th>\n",
       "      <th>Vaxx_pct</th>\n",
       "      <th>Dose1_pct</th>\n",
       "      <th>Vaxx_Booster_pct</th>\n",
       "      <th>Beds_utilization</th>\n",
       "      <th>Bed_covid_pct</th>\n",
       "      <th>Bed_covid_utilization</th>\n",
       "      <th>ICU_bed_covid_Adult_UTIL</th>\n",
       "      <th>ICU_bed_Adult_UTIL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>1</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>32.539527</td>\n",
       "      <td>-86.644082</td>\n",
       "      <td>93.985389</td>\n",
       "      <td>20310.010918</td>\n",
       "      <td>288.174122</td>\n",
       "      <td>15.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>29372.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>38.6</td>\n",
       "      <td>48.5</td>\n",
       "      <td>26.9</td>\n",
       "      <td>73.252732</td>\n",
       "      <td>11.459204</td>\n",
       "      <td>8.384716</td>\n",
       "      <td>23.277799</td>\n",
       "      <td>85.995844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>1</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>30.727750</td>\n",
       "      <td>-87.722071</td>\n",
       "      <td>140.417022</td>\n",
       "      <td>18293.808291</td>\n",
       "      <td>266.088499</td>\n",
       "      <td>10.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>31203.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>47.8</td>\n",
       "      <td>60.6</td>\n",
       "      <td>28.2</td>\n",
       "      <td>73.252732</td>\n",
       "      <td>11.459204</td>\n",
       "      <td>8.384716</td>\n",
       "      <td>23.277799</td>\n",
       "      <td>85.995844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>31.868263</td>\n",
       "      <td>-85.387129</td>\n",
       "      <td>27.893734</td>\n",
       "      <td>16199.465284</td>\n",
       "      <td>328.121202</td>\n",
       "      <td>28.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>18461.0</td>\n",
       "      <td>53.9</td>\n",
       "      <td>11.2</td>\n",
       "      <td>42.1</td>\n",
       "      <td>51.8</td>\n",
       "      <td>23.7</td>\n",
       "      <td>73.252732</td>\n",
       "      <td>11.459204</td>\n",
       "      <td>8.384716</td>\n",
       "      <td>23.277799</td>\n",
       "      <td>85.995844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>1</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>32.996421</td>\n",
       "      <td>-87.125115</td>\n",
       "      <td>35.976546</td>\n",
       "      <td>20612.664106</td>\n",
       "      <td>424.220773</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>20199.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>7.9</td>\n",
       "      <td>32.9</td>\n",
       "      <td>40.2</td>\n",
       "      <td>26.1</td>\n",
       "      <td>73.252732</td>\n",
       "      <td>11.459204</td>\n",
       "      <td>8.384716</td>\n",
       "      <td>23.277799</td>\n",
       "      <td>85.995844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Blount</td>\n",
       "      <td>1</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>33.982109</td>\n",
       "      <td>-86.567906</td>\n",
       "      <td>89.676285</td>\n",
       "      <td>19766.195137</td>\n",
       "      <td>342.406530</td>\n",
       "      <td>14.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>22656.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>35.9</td>\n",
       "      <td>26.2</td>\n",
       "      <td>73.252732</td>\n",
       "      <td>11.459204</td>\n",
       "      <td>8.384716</td>\n",
       "      <td>23.277799</td>\n",
       "      <td>85.995844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State   County  Metro_Status    FIPS        Lat      Long_  \\\n",
       "0  Alabama  Autauga             1  1001.0  32.539527 -86.644082   \n",
       "1  Alabama  Baldwin             1  1003.0  30.727750 -87.722071   \n",
       "2  Alabama  Barbour             0  1005.0  31.868263 -85.387129   \n",
       "3  Alabama     Bibb             1  1007.0  32.996421 -87.125115   \n",
       "4  Alabama   Blount             1  1009.0  33.982109 -86.567906   \n",
       "\n",
       "   Population_Density     Cases_pct   Death_pct  EP_POV  EP_UNEMP   EP_PCI  \\\n",
       "0           93.985389  20310.010918  288.174122    15.4       4.2  29372.0   \n",
       "1          140.417022  18293.808291  266.088499    10.6       4.4  31203.0   \n",
       "2           27.893734  16199.465284  328.121202    28.9       9.5  18461.0   \n",
       "3           35.976546  20612.664106  424.220773    14.0       7.5  20199.0   \n",
       "4           89.676285  19766.195137  342.406530    14.4       4.1  22656.0   \n",
       "\n",
       "   EP_MINRTY  EP_UNINSUR  Vaxx_pct  Dose1_pct  Vaxx_Booster_pct  \\\n",
       "0       25.0         7.1      38.6       48.5              26.9   \n",
       "1       17.0        10.2      47.8       60.6              28.2   \n",
       "2       53.9        11.2      42.1       51.8              23.7   \n",
       "3       25.4         7.9      32.9       40.2              26.1   \n",
       "4       12.9        11.0      29.7       35.9              26.2   \n",
       "\n",
       "   Beds_utilization  Bed_covid_pct  Bed_covid_utilization  \\\n",
       "0         73.252732      11.459204               8.384716   \n",
       "1         73.252732      11.459204               8.384716   \n",
       "2         73.252732      11.459204               8.384716   \n",
       "3         73.252732      11.459204               8.384716   \n",
       "4         73.252732      11.459204               8.384716   \n",
       "\n",
       "   ICU_bed_covid_Adult_UTIL  ICU_bed_Adult_UTIL  \n",
       "0                 23.277799           85.995844  \n",
       "1                 23.277799           85.995844  \n",
       "2                 23.277799           85.995844  \n",
       "3                 23.277799           85.995844  \n",
       "4                 23.277799           85.995844  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EMMYTABLE = ['State', 'County', 'Metro_Status',\n",
    "#                         'FIPS','Lat','Long_', \n",
    "#                         'Population_Density', 'Cases_pct', 'Death_pct',\n",
    "#                        'EP_POV', 'EP_UNEMP', 'EP_PCI',\n",
    "#                        'EP_MINRTY', 'EP_UNINSUR', \n",
    "#                        'Vaxx_pct', 'Dose1_pct', 'Vaxx_Booster_pct',\n",
    "#                        'Beds_utilization', 'Bed_covid_pct',\n",
    "#                        'Bed_covid_utilization', 'ICU_bed_covid_Adult_UTIL',\n",
    "#                        'ICU_bed_Adult_UTIL'] \n",
    "\n",
    "# C19_View[EMMYTABLE].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e95b00",
   "metadata": {},
   "source": [
    "#### XXXX XXX\n",
    "1. XXXX XXX\n",
    "2. XXXX XXX\n",
    "3. XXXX XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe4e454",
   "metadata": {},
   "source": [
    "# Specify Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67ee8aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Map = ['FIPS','EP_UNEMP']\n",
    "\n",
    "# USED FOR: All_Variables cluster\n",
    "Relavant_Attributes = ['Death_pct','Population_Density', \n",
    "                       'EP_POV', 'EP_UNEMP', 'EP_PCI',\n",
    "                       'EP_MINRTY', 'EP_UNINSUR', \n",
    "                       'Vaxx_pct', 'Dose1_pct', 'Vaxx_Booster_pct',\n",
    "                       'Beds_utilization', 'Bed_covid_pct',\n",
    "                       'Bed_covid_utilization', 'ICU_bed_covid_Adult_UTIL',\n",
    "                       'ICU_bed_Adult_UTIL']\n",
    "# ALL Location and object varaiables have been removed from \"Relavant_Attributes\" Eg=>\n",
    "# Metro_Status\n",
    "# Cases_pct\n",
    "# State_Abr\n",
    "# State\n",
    "# County\n",
    "# FIPS\n",
    "# Lat\n",
    "# Long_\n",
    "\n",
    "\n",
    "# USED FOR:\n",
    "# both Population_Density & loction based variables have been removed\n",
    "No_Population_Density = ['Death_pct',\n",
    "                       'EP_POV', 'EP_UNEMP', 'EP_PCI',\n",
    "                       'EP_MINRTY', 'EP_UNINSUR', \n",
    "                       'Vaxx_pct', 'Dose1_pct', 'Vaxx_Booster_pct',\n",
    "                       'Beds_utilization', 'Bed_covid_pct',\n",
    "                       'Bed_covid_utilization', 'ICU_bed_covid_Adult_UTIL',\n",
    "                       'ICU_bed_Adult_UTIL']\n",
    "\n",
    "# USED FOR: \n",
    "# both (state level) bed & loction based variables have been removed\n",
    "No_Bed_Attributes = ['Death_pct','Population_Density', \n",
    "                       'EP_POV', 'EP_UNEMP', 'EP_PCI',\n",
    "                       'EP_MINRTY', 'EP_UNINSUR', \n",
    "                       'Vaxx_pct', 'Dose1_pct', 'Vaxx_Booster_pct']\n",
    "\n",
    "# NO Population_Density’, state level ‘Bed’ attributes and attributes which could be used by the ML model to identify ‘Location’.\n",
    "No_Bed_Population = ['Death_pct', \n",
    "                       'EP_POV', 'EP_UNEMP', 'EP_PCI',\n",
    "                       'EP_MINRTY', 'EP_UNINSUR', \n",
    "                       'Vaxx_pct', 'Dose1_pct', 'Vaxx_Booster_pct']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932d0e15",
   "metadata": {},
   "source": [
    "# Choropleth Maps (Folium)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e248cdbf",
   "metadata": {},
   "source": [
    "#### READ/ MODIFY/ WRITE JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64919a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JsonFile = r'/Users/emmanueljumbo/dataScience/python/Dissertation/experimentation/data/Original_County_Boundary_files/us-county-boundaries.geojson'\n",
    "# #JsonFile = r'/Users/emmanueljumbo/dataScience/python/Dissertation/experimentation/data/Original_County_Boundary_files/us-county-boundaries.json'\n",
    "\n",
    "# #--READ JSON File--\n",
    "# with open(JsonFile) as file:    #When Using .Geojson file\n",
    "#   data = json.load(file)\n",
    "# # with open(JsonFile) as file:   #When Using .json file\n",
    "# #   data = json.load(file)\n",
    "\n",
    "# #--MODIFY File--\n",
    "# for id in data['features']:     #When Using .Geojson file\n",
    "#     id['properties']['geoid'] = float(id['properties']['geoid']) #Float\n",
    "# #    id['properties']['geoid'] = int(id['properties']['geoid'])   #int\n",
    "# #for id in data:                 #When Using .json file\n",
    "# #    id['fields']['geoid'] = float(id['fields']['geoid'])\n",
    "\n",
    "# #--WRITE JSON File--\n",
    "# with open('New_us-county-boundaries.json', 'w') as file:\n",
    "#   json.dump(data, file, indent=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #                     What And Why:\n",
    "# # Fristly Only ONE of the above functions Should be run at a time. \n",
    "# # Each of the above functions were created to read a json/ Geojson file, modify it \n",
    "# # (change the “geoid” attribute from a string to a float) and then make/write a new \n",
    "# # JSON file. This is needed cause it lets me match(“key_on:”) my dataset key(FIPs) to \n",
    "# # the .json county boundary dataset key(GEOID).\n",
    "# #\n",
    "# # IDEA FROM= \n",
    "# #        ---JSON Datasets FOR US County & State Boundaries---\n",
    "# # Opendatasoft= https://public.opendatasoft.com/explore/dataset/us-county-boundaries/information/?disjunctive.statefp&disjunctive.countyfp&disjunctive.name&disjunctive.namelsad&disjunctive.stusab&disjunctive.state_name&sort=stusab&dataChart=eyJxdWVyaWVzIjpbeyJjb25maWciOnsiZGF0YXNldCI6InVzLWNvdW50eS1ib3VuZGFyaWVzIiwib3B0aW9ucyI6eyJkaXNqdW5jdGl2ZS5zdGF0ZWZwIjp0cnVlLCJkaXNqdW5jdGl2ZS5jb3VudHlmcCI6dHJ1ZSwiZGlzanVuY3RpdmUubmFtZSI6dHJ1ZSwiZGlzanVuY3RpdmUubmFtZWxzYWQiOnRydWUsImRpc2p1bmN0aXZlLnN0dXNhYiI6dHJ1ZSwiZGlzanVuY3RpdmUuc3RhdGVfbmFtZSI6dHJ1ZX19LCJjaGFydHMiOlt7ImFsaWduTW9udGgiOnRydWUsInR5cGUiOiJjb2x1bW4iLCJmdW5jIjoiQVZHIiwieUF4aXMiOiJhbGFuZCIsInNjaWVudGlmaWNEaXNwbGF5Ijp0cnVlLCJjb2xvciI6IiNGRjUxNUEifV0sInhBeGlzIjoic3RhdGVmcCIsIm1heHBvaW50cyI6NTAsInNvcnQiOiIifV0sInRpbWVzY2FsZSI6IiIsImRpc3BsYXlMZWdlbmQiOnRydWUsImFsaWduTW9udGgiOnRydWV9&location=4,43.96119,-79.36523&basemap=jawg.light\n",
    "# # HIFLD=        https://hifld-geoplatform.opendata.arcgis.com/datasets/geoplatform::us-county-boundaries/about\n",
    "# #        ---Modify JSON File---\n",
    "# # https://www.geeksforgeeks.org/reading-and-writing-json-to-a-file-in-python/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ca369f",
   "metadata": {},
   "source": [
    "#### PLOT Choropleth Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6af75ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #latitude and Longitude the map is to focus on when loaded\n",
    "# ChoroplethMap = folium.Map(location = [40, -95], zoom_start = 4) \n",
    "\n",
    "# # Import data on county boundaries (CountyBoundaries_df)\n",
    "# # Geo_Data = r'/Users/emmanueljumbo/dataScience/python/Dissertation/experimentation/data/us-county-boundaries.geojson'\n",
    "# Geo_Data = r'/Users/emmanueljumbo/dataScience/python/Dissertation/experimentation/data/New_us-county-boundaries.json'\n",
    "\n",
    "# # Variable from NON_TimeSeries_df to be plotted\n",
    "# Attribute_data_For_Plotting = C19_View[Test_Map]\n",
    "\n",
    "# # Plot Choropleth Map\n",
    "# folium.Choropleth(\n",
    "#     geo_data = Geo_Data,                  #Boundaries of a geographic area                   \n",
    "#     name = \"choropleth\",\n",
    "#     data = Attribute_data_For_Plotting,   #Stats to be displayed                          \n",
    "#     columns = [\"FIPS\", \"EP_UNEMP\"],       #Matching Key and a single stat from my CSV File\n",
    "#     fill_color = \"YlGn\",     \n",
    "#     fill_opacity = 0.7,\n",
    "#     line_opacity = .1,\n",
    "#     key_on = \"feature.properties.geoid\",  #Matching Key from geo location JSON file\n",
    "#     #key_on = \"fields.geoid\",\n",
    "#     legend_name = \"CHANGE NAME Rate (%)\",\n",
    "# ).add_to(ChoroplethMap)                                 \n",
    "  \n",
    "# ChoroplethMap.save('/Users/emmanueljumbo/dataScience/python/Dissertation/experimentation/maps/final_map.html') #Save newly created map as a .html file\n",
    "# # ChoroplethMap  #This will create map in this Pyhton notebook (P.S. It may crash notebook)\n",
    "\n",
    "\n",
    "\n",
    "# #                     What And Why:\n",
    "# # Made to visualise data on map. Black spots on the map represent counties I no longer have data on.\n",
    "# # rows for these missing counties were removed during the handling of null values & outlier handling.\n",
    "# # such as counties in puerto rico(had all null values) or Rio Arriba in New Mexico. \n",
    "# #\n",
    "# # Began by installing Folium => [conda install -c conda-forge folium]\n",
    "# # then import Folium => [import folium]\n",
    "# #\n",
    "# # IDEA FROM= \n",
    "# #        ---ChoroplethMap---\n",
    "# # ChoroplethMap=  https://www.geeksforgeeks.org/visualizing-geospatial-data-using-folium-in-python/?ref=gcse\n",
    "# #        ---JSON Datasets FOR US County & State Boundaries---\n",
    "# # Opendatasoft=  https://public.opendatasoft.com/explore/dataset/us-county-boundaries/information/?disjunctive.statefp&disjunctive.countyfp&disjunctive.name&disjunctive.namelsad&disjunctive.stusab&disjunctive.state_name&sort=stusab&dataChart=eyJxdWVyaWVzIjpbeyJjb25maWciOnsiZGF0YXNldCI6InVzLWNvdW50eS1ib3VuZGFyaWVzIiwib3B0aW9ucyI6eyJkaXNqdW5jdGl2ZS5zdGF0ZWZwIjp0cnVlLCJkaXNqdW5jdGl2ZS5jb3VudHlmcCI6dHJ1ZSwiZGlzanVuY3RpdmUubmFtZSI6dHJ1ZSwiZGlzanVuY3RpdmUubmFtZWxzYWQiOnRydWUsImRpc2p1bmN0aXZlLnN0dXNhYiI6dHJ1ZSwiZGlzanVuY3RpdmUuc3RhdGVfbmFtZSI6dHJ1ZX19LCJjaGFydHMiOlt7ImFsaWduTW9udGgiOnRydWUsInR5cGUiOiJjb2x1bW4iLCJmdW5jIjoiQVZHIiwieUF4aXMiOiJhbGFuZCIsInNjaWVudGlmaWNEaXNwbGF5Ijp0cnVlLCJjb2xvciI6IiNGRjUxNUEifV0sInhBeGlzIjoic3RhdGVmcCIsIm1heHBvaW50cyI6NTAsInNvcnQiOiIifV0sInRpbWVzY2FsZSI6IiIsImRpc3BsYXlMZWdlbmQiOnRydWUsImFsaWduTW9udGgiOnRydWV9&location=4,43.96119,-79.36523&basemap=jawg.light\n",
    "# # HIFLD=         https://hifld-geoplatform.opendata.arcgis.com/datasets/geoplatform::us-county-boundaries/about"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47118d7c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# MachineLearning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29371b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating Independent(X) & Dependent(Y) Variables sets\n",
    "\n",
    "X = C19_View[No_Bed_Population].values # Variables being used to create cluster\n",
    "Y = C19_View['Metro_Status'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b2038db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instance Normalization/ Scaling\n",
    "\n",
    "scale = StandardScaler()\n",
    "\n",
    "X = scale.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3336d60",
   "metadata": {},
   "source": [
    "#### PCA (Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "471904be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import IncrementalPCA\n",
    "# pca = IncrementalPCA(n_components = 2)\n",
    "# X = pca.fit_transform(X)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "k = 4 #Number of clusters\n",
    "\n",
    "pca = PCA(n_components = k)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "#Dimension reduction by means of compressing the dataset and then holding onto only the most relevant\n",
    "#info which is then used to create \"principal components\"\n",
    "#  (so from a large amount of correlated variables to a smaller amount of uncorrelated variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03bbff4",
   "metadata": {},
   "source": [
    "#### K-Means Clustering (Unsupervised Machine Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d0e80b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, ..., 0, 1, 0], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans #Training Cluster Model\n",
    "\n",
    "k #Number of clusters\n",
    "\n",
    "kMeans = KMeans(n_clusters=k, random_state=42).fit(X)\n",
    "pred_cluster = kMeans.fit_predict(X) #Pass our data to train our model\n",
    "pred_cluster\n",
    "\n",
    "# This is an example of hard clustering where in each instance is assigning to a single cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d335816",
   "metadata": {},
   "source": [
    "## Plot Kmeans Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c78762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Clusters in new column\n",
    "C19_View['Clusters'] = kMeans.labels_\n",
    "\n",
    "# C19_View.head()\n",
    "# C19_View['Clusters'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "023b2ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.features.Choropleth at 0x7fd9039cfac0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Map = ['FIPS','Clusters']\n",
    "\n",
    "\n",
    "ChoroplethMap = folium.Map(location = [40, -95], zoom_start = 4) \n",
    "\n",
    "Geo_Data = r'/Users/emmanueljumbo/dataScience/python/Dissertation/experimentation/data/New_us-county-boundaries.json'\n",
    "\n",
    "Attribute_data_For_Plotting = C19_View[Test_Map]\n",
    "\n",
    "\n",
    "folium.Choropleth(\n",
    "        geo_data = Geo_Data,                  #Boundaries of a geographic area                   \n",
    "        name = \"choropleth\",\n",
    "        data = Attribute_data_For_Plotting,   #Stats to be displayed                          \n",
    "        columns = [\"FIPS\", \"Clusters\"],       #Matching Key and a single stat from my CSV File\n",
    "        fill_color = \"YlGnBu\",\n",
    "        fill_opacity = 0.7,\n",
    "        line_opacity = .1,\n",
    "        key_on = \"feature.properties.geoid\",  #Matching Key from geo location JSON file\n",
    "        legend_name = \"Clusters\",\n",
    "    ).add_to(ChoroplethMap)                                 \n",
    "\n",
    "\n",
    "# ChoroplethMap.save('/Users/emmanueljumbo/dataScience/python/Dissertation/experimentation/maps/Name_Not_given.html') #This will create map file in map folder(Change names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d7d8ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##                              OBSERVATION\n",
    "\n",
    "\n",
    "\n",
    "# All_Variables:\n",
    "# This cluster was created using all attributes expect does which could be used by the ML model to identify Location, such as FIP codes.\n",
    "# -most coastal region appear to all be of the same colour/ cluster (dark blue)\n",
    "# -Certain clusters(light blue) form into the shape of states. Eg Texas, Nevada, Washington Is that cause of the state level bed data?\n",
    "# -(Light yellow) clusters are focused at the bottom of the US main land.  Is the above cause of latitude(vitamin D)?\n",
    "# -(Light green) clusters are focused at the upper and middle regions of the US main land   \n",
    "\n",
    "\n",
    "# No_Population_Density:\n",
    "# This cluster was created using all attributes expect ‘Population_Density’ and attributes which could be used by the ML model to identify ‘Location’.\n",
    "# -most coastal region appear to all be of the same colour/ cluster (dark blue)\n",
    "# -Certain clusters(light blue) form into the shape of states. Eg Texas, Nevada, Washington Is that cause of the state level bed data?\n",
    "# -(Light green) clusters are focused at the bottom of the US main land. Is the above cause of latitude(vitamin D)?\n",
    "# -(Light yellow) clusters are focused at the upper and middle regions of the US main land   \n",
    "\n",
    "\n",
    "# No_Bed_Attributes:\n",
    "# This cluster was created using all attributes expect state level ‘Bed’ attributes and attributes which could be used by the ML model to identify ‘Location’.\n",
    "# -most coastal region appear to all be of the same colour/ cluster (Light yellow)\n",
    "# -No more shape of states can be seen. Cause state level data has been removed.\n",
    "# -(Light green) clusters are focused at the bottom of the US main land. Is the above cause of latitude(vitamin D)?\n",
    "# -(dark blue) clusters are scattered across the upper and middle regions of the US main land but still remaining in clumps, side by side each other\n",
    "\n",
    "# No_Bed_Population:\n",
    "# This cluster was created using all attributes expect ‘Population_Density’, state level ‘Bed’ attributes and attributes which could be used by the ML model to identify ‘Location’.\n",
    "# -(dark blue) clusters mostly appear at coastal regions.\n",
    "# -No more shape of states can be seen. Cause state level data has been removed.\n",
    "# -(Light green) clusters are focused at the bottom of the US main land. Is the above cause of latitude(vitamin D)?\n",
    "# -(light Yellow) clusters are scattered across the upper and middle regions of the US main land but still remaining in clumps, side by side each other\n",
    "\n",
    "\n",
    "# List of Clusters Types:\n",
    "# (dark blue)\n",
    "# (light blue)\n",
    "# (Light yellow) \n",
    "# (Light green) \n",
    "\n",
    "\n",
    "\n",
    "# SUMMARY\n",
    "# Even after taking out; variables which indicate location, State level variables  and  population density variable (proxy for metro and non metro).  \n",
    "# Positive autocorrelation (Custers gathered in clumps) remained present across all 4 maps.  \n",
    "# Rather than becoming negative spatial autocorrelation (dissimilar values next to each other like chest board)\n",
    "\n",
    "# Probable reason behind this pattern maybe:\n",
    "# - individual state policies,\n",
    "# - population's access to vaccines and health insurance. \n",
    "# - population's willingness to get vaccines or follow government’s covid guideline\n",
    "\n",
    "# SEE NOTE BOOK (31st March) For “Future Work” Suggestion.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8bbae5",
   "metadata": {},
   "source": [
    "## CHECK Kmeans Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f3cddf",
   "metadata": {},
   "source": [
    "#### Inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83359da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array where the model stores predictions\n",
    "pred_cluster is kMeans.labels_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50e570a",
   "metadata": {},
   "source": [
    "#### Inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4def54ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11564.697980192966"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kMeans.inertia_\n",
    "\n",
    "# Inertia\n",
    "# used to calculate the performance of the clusters created by K-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9213803c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11564.697980192966"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative Inertia\n",
    "kMeans.score(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
